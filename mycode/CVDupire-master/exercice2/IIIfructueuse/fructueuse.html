<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>De fructueuses perspectives de conciliation entre développement et éthique</title>
    <link rel="stylesheet" href="../ex2.css">
</head>
<body>
    <h2>        
        III. De fructueuses perspectives de conciliation entre développement et éthique    
    </h2>

    <h3>
        A. La législation Canadienne en matière de gestion de la politique sur les services, le numérique et
        la prise de décision automatisée
    </h3> 
    <p>
        On peut voir actuellement qu’au Canada, la mise en oeuvre d’audits incluant les enjeux de discriminations est
        obligatoire pour les institutions publiques depuis le 1er avril 2020 dans le cadre de la Loi sur la gestion des finances
        publiques, la Politique sur les services et le numérique23 et la Directive sur la prise de décision automatisée24. Il fut
        notamment mis en œuvre une place afin d’accompagner les administrations dans leurs analyses d’impact nommé
        IEA (en français, Évaluation de l’Incidence Algorithmique).
        Concrètement, la directive permet de déterminer le niveau de l’évaluation de l’incidence par quatre niveaux
        d’incidence25: probable, vraisemblablement modérée, vraisemblablement élevée, vraisemblablement très élevée.
        Sachant que les décisions de niveau IV mèneront souvent à des effets irréversibles et permanents.
        Ensuite, le niveau d’incidence permettra de déterminer les exigences d’évaluation26 : examens par les pairs, avis,
        maillon humain de la prise de décisions, exigences en matière d’explication, formation, planification des mesures
        d’urgence et, approbation de l’exploitation du système.
    </p>
    <h3>
        B. Le projet parlementaire européen en matière d’IA
    </h3>
    <p>
        Le 21 avril 2021, la Commission européenne a présenté une proposition de règlement ayant pour finalité d’établir
        des règles harmonisées en matière d’intelligence artificielle.
        S’inscrivant dans le prolongement de la publication par la Commission européenne d’un Livre Blanc sur
        l’intelligence artificielle28 visant à définir les différentes options stratégiques en matière de promotion de l’IA ainsi
        que ses risques associés, la proposition poursuit quatre objectifs :
        - veiller à la sûreté des systèmes d’IA sur le marché de l’Union ainsi qu’au respect des droits fondamentaux et
        les valeurs de l’Union ;
        - assurer la sécurité juridique pour faciliter l’investissement et l’innovation ;
        - faciliter le développement d’un marché unique et prévenir sa fragmentation par l’utilisation d’IA sûres et
        dignes de confiance.
        Au travers de ce projet de règlement, la Commission a cherché à trouver un équilibre entre expansion du marché
        unique européen de l’IA et adoption d’un cadre réglementaire conciliant les différents droits et intérêts en jeu. Afin
        de construire une Europe adaptée à l'ère du numérique, la Commission a souhaité proposer de nouvelles règles et
        actions en faveur de l'excellence et de la confiance dans l'intelligence artificielle. Dans ce cadre, l’adoption
        d’exigences minimales fut proposée afin de concilier les risques liés à l’IA tout en adoptant un cadre flexible pouvant
        s’adapter aux futurs développements technologiques.
        La proposition de la Commission prévoit notamment d’établir un cadre réglementaire différencié en fonction
        des risques présentés pour les utilisations. Ainsi, une distinction est faite entre :
        - les utilisations interdites car présentant des risques inacceptables,
        - les utilisations réglementées car présentant des risques élevés et,
        - les utilisations soumises à des obligations de transparence car présentant certains risques de manipulation.
        La proposition engloberait en outre tout « logiciel développé à l’aide d’une ou de plusieurs des techniques et
        approches énumérées à l’annexe I et qui peut, pour un ensemble d’objectifs définis par l’homme, générer des résultats
        tels que du contenu, des prédictions, des recommandations ou des décisions influençant les environnements avec
        lesquels ils interagissent ».
        L’annexe I contient ainsi une liste de formes d’IA regroupant les approches d’apprentissage automatique («
        machine learning »), les approches basées sur la logique et la connaissance, et les approches statistiques.
        Point réellement innovant, la proposition aurait aussi pour objectif l’établissement de codes de conduite
        contraignants par les fournisseurs de systèmes d’IA ne présentant pas de risques élevés ainsi que la création d’un
        Conseil européen de l’intelligence artificielle (« European Artificial Intelligence Board »), composé de représentants
        des États membres et de la Commission.
        Enfin, le Parlement européen et les États membres devront adopter la proposition de règlement dans le cadre de
        la procédure législative ordinaire afin que le règlement devienne applicable dans toute l'UE dans un délai de 24 mois
        suivant son entrée en vigueur.
    </p>
    <h3>
        C. Le manuel sur la protection des données et la confidentialité pour les développeurs d'IA en Inde
    </h3>
    <p>
        L'Inde exploite le potentiel de la technologie et prévoit de devenir une économie numérique de 1 000 milliards
        d'euros en 2025. Avec ses près de 5 millions d'ingénieurs en technologie, l'Inde est l'un des plus grands réservoirs de
        talents informatiques au monde. L'adoption de lignes directrices pour le développement responsable de l'IA est donc
        très importante, devant notamment passer par l’éducation des développeurs et des architectes de solutions en matière
        de bonnes pratiques afin de répondre aux attentes de la société civile et donc des utilisateurs sur le long terme.
        L’intelligence artificielle s'imposant comme une technologie fondamentale qui alimente de nombreuses
        solutions électroniques de sociétés indiennes, les risques d’abus de cette technologie ont engendré une nécessité
        d’élaborer des politiques inclusives mais aussi des initiatives axées sur les praticiens afin d’intégrer de façon proactive
        de pratiques éthique et de confidentialité by design dans les solutions d’IA.
        Dans ce cadre, le 15 juillet 2021 le Conseil de la sécurité des données Indienne 29
        en collaboration avec
        l’Association allemande pour la coopération internationale (Deutsche Gesellschaft für Internationale
        Zusammenarbeit (GIZ) GmbH)30, la fondation Digital India31 et le Koan Advisory Group a publié un manuel pour
        aider les développeurs à élaborer des solutions d'IA qui tiennent compte des considérations éthiques et de la protection
        de la vie privée.
        Ce guide principalement destiné aux développeurs d'IA qui sont déjà familiarisés avec les processus
        d'apprentissage automatique (ML), comme les start-ups en phase de démarrage, permettra de limiter les problèmes
        pouvant survenir ultérieurement et engendrer des complications obligeant notamment les sociétés et starts up à
        abandonner la conception du produit ou de l’application par sa vision interdisciplinaire.
        Outre les explications simples sur l’éthique de l’IA, il comprend : des listes de contrôle pour les développeurs à
        différents points d'intervention, des bonnes pratiques, et des exemples de défis auxquels les développeurs peuvent
        être confrontés.
        Fait important, ce manuel évalue notamment l'impact du projet de loi sur la protection des données personnelles,
        2019 (projet de loi PDP Indien)33 ainsi que de la réglementation actuelle en Inde.
    </p>
    <br>

    <a class="retour_accueil" href="../ex2.html">Retour à l'accueil</a>

</body>
</html>